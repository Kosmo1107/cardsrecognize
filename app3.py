import streamlit as st
import faiss
import torch
import open_clip
from PIL import Image
import numpy as np
import os

# --- 1ï¸âƒ£ ãƒ¢ãƒ‡ãƒ«æº–å‚™ ---
device = "cuda" if torch.cuda.is_available() else "cpu"
model, _, preprocess = open_clip.create_model_and_transforms('ViT-H-14', pretrained='laion2b_s32b_b79k')
model = model.to(device)
model.eval()

# --- 2ï¸âƒ£ cards ãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰ç”»åƒã‚’èª­ã¿è¾¼ã‚€ ---
image_folder = "cards"
image_paths = [os.path.join(image_folder, f) for f in os.listdir(image_folder) if f.lower().endswith(('jpg','png','jpeg'))]
if len(image_paths) == 0:
    st.error("âš ï¸ 'cards' ãƒ•ã‚©ãƒ«ãƒ€ã«ç”»åƒãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
else:
    st.success(f"{len(image_paths)} æšã®ãƒˆãƒ¬ã‚«ç”»åƒã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")

# --- 3ï¸âƒ£ ç‰¹å¾´é‡ã‚’æŠ½å‡ºã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä½œæˆ ---
@st.cache_resource
def build_index():
    features = []
    for path in image_paths:
        img = Image.open(path).convert("RGB")
        img_tensor = preprocess(img).unsqueeze(0).to(device)
        with torch.no_grad():
            feat = model.encode_image(img_tensor)
            feat = feat / feat.norm(dim=-1, keepdim=True)
            features.append(feat.cpu().numpy().astype("float32"))
    features = np.vstack(features)

    index = faiss.IndexFlatIP(features.shape[1])
    index.add(features)
    return index, features

index, features = build_index()

# --- 4ï¸âƒ£ æ¤œç´¢UI ---
st.title("ğŸ“¸ Hongjoongãƒˆãƒ¬ã‚«æ¤œç´¢")
st.write("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”»åƒã¨æœ€ã‚‚é¡ä¼¼ã™ã‚‹ãƒˆãƒ¬ã‚«ã‚’æ¤œç´¢ã—ã¾ã™ã€‚")

uploaded = st.file_uploader("ãƒˆãƒ¬ã‚«å†™çœŸã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=["jpg", "png", "jpeg"])

if uploaded:
    query_img = Image.open(uploaded).convert("RGB")
    st.image(query_img, caption="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”»åƒ", width=300)

    # ç‰¹å¾´é‡æŠ½å‡º
    image_tensor = preprocess(query_img).unsqueeze(0).to(device)
    with torch.no_grad():
        q_feat = model.encode_image(image_tensor)
        q_feat = q_feat / q_feat.norm(dim=-1, keepdim=True)

    q_feat = q_feat.cpu().numpy().astype("float32")

    # é¡ä¼¼æ¤œç´¢ï¼ˆã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ï¼‰
    D, I = index.search(q_feat, k=min(5, len(image_paths)))

    st.subheader("ğŸ” é¡ä¼¼ãƒˆãƒ¬ã‚«å€™è£œ")

    for rank, idx in enumerate(I[0]):
        match_path = image_paths[idx]
        similarity = D[0][rank]
    
    # --- ğŸ’¡ ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ã‚«ãƒ¼ãƒ‰åã‚’æ•´å½¢ ---
    filename = os.path.basename(match_path)
    card_name = os.path.splitext(filename)[0]  # æ‹¡å¼µå­é™¤å»
    card_name = card_name.replace("_", " ").replace("-", " ").title()  # è¦‹ã‚„ã™ã

    # --- ğŸ“¸ è¡¨ç¤º ---
    st.image(
        match_path,
        caption=f"å€™è£œ {rank+1}: {card_name}\né¡ä¼¼åº¦ {similarity:.3f}",
        width=300,
    )

# --- ğŸ ä¸€è‡´åº¦ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ ---
best_score = float([0][0])
best_card = os.path.splitext(os.path.basename(image_paths[[0][0]]))[0]

if best_score > 0.98:
    st.success(f"âœ… æœ€ã‚‚ä¸€è‡´ã—ãŸã‚«ãƒ¼ãƒ‰: {best_card}ï¼ˆé¡ä¼¼åº¦ {best_score:.3f}ï¼‰")
elif best_score > 0.8:
    st.info(f"ğŸŸ© é¡ä¼¼ã‚«ãƒ¼ãƒ‰: {best_card}ï¼ˆé¡ä¼¼åº¦ {best_score:.3f}ï¼‰")
else:
    st.warning(f"âš ï¸ ä¸€è‡´åº¦ãŒä½ã„ï¼ˆ{best_score:.3f}ï¼‰ â†’ ç•°ãªã‚‹ã‚«ãƒ¼ãƒ‰ã®å¯èƒ½æ€§ã‚ã‚Š")
