import streamlit as st
import faiss
import torch
import open_clip
from PIL import Image
import numpy as np
import os

# --- 1ï¸âƒ£ ãƒ¢ãƒ‡ãƒ«æº–å‚™ ---
device = "cuda" if torch.cuda.is_available() else "cpu"
model, _, preprocess = open_clip.create_model_and_transforms('ViT-H-14', pretrained='laion2b_s32b_b79k')
model = model.to(device)
model.eval()

# --- 2ï¸âƒ£ cards ãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰ç”»åƒã‚’èª­ã¿è¾¼ã‚€ ---
image_folder = "cards"
image_paths = [os.path.join(image_folder, f) for f in os.listdir(image_folder) if f.lower().endswith(('jpg','png','jpeg'))]
if len(image_paths) == 0:
    st.error("âš ï¸ 'cards' ãƒ•ã‚©ãƒ«ãƒ€ã«ç”»åƒãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
else:
    st.success(f"{len(image_paths)} æšã®ãƒˆãƒ¬ã‚«ç”»åƒã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")

# --- 3ï¸âƒ£ ç‰¹å¾´é‡ã‚’æŠ½å‡ºã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä½œæˆ ---
@st.cache_resource
def build_index():
    features = []
    for path in image_paths:
        img = Image.open(path).convert("RGB")
        img_tensor = preprocess(img).unsqueeze(0).to(device)
        with torch.no_grad():
            feat = model.encode_image(img_tensor)
            feat = feat / feat.norm(dim=-1, keepdim=True)
            features.append(feat.cpu().numpy().astype("float32"))
    features = np.vstack(features)

    index = faiss.IndexFlatIP(features.shape[1])
    index.add(features)
    return index, features

index, features = build_index()

# --- 4ï¸âƒ£ æ¤œç´¢UI ---
st.title("ğŸ“¸ Hongjoongãƒˆãƒ¬ã‚«æ¤œç´¢")
st.write("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”»åƒã¨æœ€ã‚‚é¡ä¼¼ã™ã‚‹ãƒˆãƒ¬ã‚«ã‚’æ¤œç´¢ã—ã¾ã™ã€‚")

uploaded = st.file_uploader("ãƒˆãƒ¬ã‚«å†™çœŸã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=["jpg", "png", "jpeg"])

if uploaded:
    query_img = Image.open(uploaded).convert("RGB")
    st.image(query_img, caption="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”»åƒ", width=300)

    # ç‰¹å¾´é‡æŠ½å‡º
    image_tensor = preprocess(query_img).unsqueeze(0).to(device)
    with torch.no_grad():
        q_feat = model.encode_image(image_tensor)
        q_feat = q_feat / q_feat.norm(dim=-1, keepdim=True)

    q_feat = q_feat.cpu().numpy().astype("float32")

    # é¡ä¼¼æ¤œç´¢ï¼ˆã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ï¼‰
    D, I = index.search(q_feat, k=min(5, len(image_paths)))

    st.subheader("ğŸ” é¡ä¼¼ãƒˆãƒ¬ã‚«å€™è£œ")

    for rank, idx in enumerate(I[0]):
        match_path = image_paths[idx]
        similarity = D[0][rank]
        st.image(match_path, caption=f"å€™è£œ {rank+1}: {os.path.basename(match_path)}ï¼ˆé¡ä¼¼åº¦ {similarity:.4f}ï¼‰", width=300)

    best_score = float(D[0][0])
    if best_score > 0.98:
        st.success("âœ… ä¸€è‡´åº¦ãŒéå¸¸ã«é«˜ã„ï¼ï¼ˆ{best_score:.3f}")
